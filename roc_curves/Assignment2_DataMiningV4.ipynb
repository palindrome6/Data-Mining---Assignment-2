{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: right; font-weight: bold;'> March 19, 2016 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: right;'>Nitin Narayan | n.narayan@student.tue.nl | student no.0976544 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='text-align: right;'>Rodrigo Mendoza | r.a.mendoza.marin@student.tue.nl  | student no.0980103</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">Both members of the group contributed equally</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color: #0066cc\">2 Evaluation Homework</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global imports and settings\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.max_open_warning\"] = -1\n",
    "\n",
    "# Print options\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Slideshow\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {'width': 1440, 'height': 768, 'scroll': True, 'theme': 'simple'})\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0066cc\"> 2.1 Exercise 1: ROC curves </h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Plot A, B, and C on a ROC diagram. Use a number of different thresholds for C (at least 3).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "y_true = np.array([1,1,1,1,1,1,1,0,0,0,0,0,0])\n",
    "scores_a = np.array([[1,1,0,0,1,1,0,0,1,0,0,0,0]])\n",
    "scores_b = np.array([[1,1,1,1,0,1,1,0,1,0,1,0,0]])\n",
    "scores_c1 = np.array([[0.8,0.9,0.7,0.6,0.4,0.8,0.4,0.4,0.6,0.4, 0.4, 0.4,0.2]])\n",
    "scores_c2 = np.array([[0.8,0.9,0.7,0.6,0.4,0.8,0.4,0.4,0.6,0.4, 0.4, 0.4,0.2]])\n",
    "scores_c3 = np.array([[0.8,0.9,0.7,0.6,0.4,0.8,0.4,0.4,0.6,0.4, 0.4, 0.4,0.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the __thresholds: 0.5, 0.3 and 0.6__. Filter by thresholds and join them into one array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_c1 = np.where(scores_c1>0.5,1,0)\n",
    "scores_c2 = np.where(scores_c2>0.3,1,0)\n",
    "scores_c3 = np.where(scores_c3>0.6,1,0)\n",
    "scores  = np.concatenate((scores_a,scores_b,scores_c1, scores_c2, scores_c3), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute ROC curve and ROC area for each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes): # sklearn metrics\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true, scores[i], pos_label=1)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# When the roc curve path is vertical at the the beginning \n",
    "# it doesn't return you the point (0,0)\n",
    "# We add it manually for easy plotting\n",
    "# FPR = 0 / 0 + 6 = 0. \n",
    "fpr[4] = np.append(0., fpr[4])\n",
    "tpr[4] = np.append(0., tpr[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot gives different colors for each of the predictions. The dash black line is exactly in the middle (random classifier p = 0.5). The area under the curve is shown in the bottom right corner. Predicter C3 with a threshold of 0.6 has the highest ROC AUC value of $0.7857$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "names = ['A','B','C1_0.5', 'C2_0.3', 'C3_0.6']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                                   ''.format(names[i], roc_auc[i]), linewidth=2.0)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plot_margin = 0.02\n",
    "x0, x1, y0, y1 = plt.axis()\n",
    "plt.axis((x0 - plot_margin,\n",
    "          x1 + plot_margin,\n",
    "          y0 - plot_margin,\n",
    "          y1 + 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.1.2 Assume that the classes are balanced, hence P(+) = P(-􀀀) = 0.5. The cost of a false positive and false negative are CFP = 1 and CFN = 5. Which classifier is best: A, B, or C with a threshold of 0.5? Show geometrically in the ROC diagram which models are optimal under this cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we incorporate the missclasification costs given by $ cost = pos*(1–TPR)*C_{FN} + neg*FPR*C_{FP}$, for each of the predictions:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Cost_{A} &= (7)*(1-(4/7))*(5)+(6)*(1/6)*(1)  \\\\\n",
    "&= 16 \\\\\n",
    "Cost_{B} &= (7)*(1-6/7)*(5)+(6)*(1/3)*(1)  \\\\\n",
    "&= 7  \\\\\n",
    "Cost_{C_{3}} &= (7)*(1-(5/7))*(5)+(6)*(1/6)*(1)  \\\\\n",
    "&= 11\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: to obtain TPR or FPR we can use either the points from fpr[i], tpr[i] or construct the confusion matrix and then obtain TPR and FPR with the ecuations:\n",
    "$$\n",
    "\\begin{align}\n",
    "TPR &= \\frac{TP}{TP + FN}  \\\\\n",
    "FPR &= \\frac{FP}{FP + TN}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, lets look at classifier A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"0\" style=\"width : 30%; text-align: center;\">\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid white; border: 1px solid white;\"></td>\n",
    "    <td colspan=\"3\" style=\"text-align: center; border: 1px solid white;\">Predicted</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid white;\"></td>\n",
    "    <td></td>\n",
    "    <td style=\"text-align: center;\">-</td>\n",
    "    <td style=\"text-align: center;\">+</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\" style=\"text-align: center; border: 1px solid white;\">Actual</td>\n",
    "    <td style=\"text-align: center;\">-</td>\n",
    "    <td style=\"text-align: center;\">5</td>\t\t\n",
    "    <td style=\"text-align: center;\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align: center;\">+</td>\n",
    "    <td style=\"text-align: center;\">3</td>\t\t\n",
    "    <td style=\"text-align: center;\">4</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "TN &= 5 \\\\\n",
    "FP &= 1 \\\\\n",
    "FN &= 3\\\\\n",
    "TP &= 4 \\\\\n",
    "TPR_{A} &= \\frac{4}{4+3} \\\\\n",
    "&= 0.5714 \\\\\n",
    "FPR_{A} &= \\frac{1}{1+5}  \\\\\n",
    "&= 0.1660\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The classifier B has the lowest cost with $6$, hence we choose B as the best one. To show geometrically which models are optimal under this cost function we need first to calculate the slope as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "slope &= \\frac{neg*C_{FP}}{pos*C_{FN}} \\\\ \n",
    "&= \\frac{(0.5)(1)}{(0.5)(5)}  \\\\\n",
    "&= 0.20\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add on the classifier space the iso-cost line with a slope of 0.20 (black line). As we see it touches B who has actually the smallest cost among all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "names = ['A','B','C1_0.5', 'C2_0.3', 'C3_0.6']\n",
    "for i in range(3):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                                   ''.format(names[i], roc_auc[i]), linewidth=2.0)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plot_margin = 0.02\n",
    "x0, x1, y0, y1 = plt.axis()\n",
    "plt.axis((x0 - plot_margin,\n",
    "          x1 + plot_margin,\n",
    "          y0 - plot_margin,\n",
    "          y1 + 0))\n",
    "x = np.linspace(0, 1, 3)\n",
    "y = 0.2 * (x) + 0.80 # line with 0.2 slope\n",
    "plt.plot(x, y, linewidth=5.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Draw the convex hull of the classifiers A, B, C. Which classifiers are never optimal? Which classifiers are optimal in a certain environment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scipy.spatial as the convex hull algorithm. Load all points from FPR and TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #convexHull\n",
    "points = np.vstack((fpr[0], tpr[0])).T\n",
    "for i in range(n_classes): # the first 3 classifiers\n",
    "    points = np.append(points, np.vstack((fpr[i], tpr[i])).T, axis=0)\n",
    "hull = ConvexHull(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the __convex hull __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.style.use('ggplot')\n",
    "#Add the 3 roc curves\n",
    "names = ['A','B','C1_0.5','C2_0.3','C3_0.6']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                                   ''.format(names[i], roc_auc[i]), linewidth=1.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Draw line path of convex hull, skipping the first path \"diagonal\"\n",
    "iterpoint = iter(hull.simplices)\n",
    "next(iterpoint)\n",
    "for simplex in iterpoint:\n",
    "    plt.plot(points[simplex, 0], points[simplex, 1], '#ff3300', lw=6, alpha=0.5)\n",
    "    \n",
    "# dots\n",
    "plt.plot(points[:,0], points[:,1], 'o', color = '#7a7a52', alpha=0.5)\n",
    "#middle line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "#margins\n",
    "plot_margin = 0.02\n",
    "x0, x1, y0, y1 = plt.axis()\n",
    "plt.axis((x0 - plot_margin,\n",
    "          x1 + plot_margin,\n",
    "          y0 - plot_margin,\n",
    "          y1 + plot_margin))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers under the convex hulll are sub-optimal, in our case A never touches the convex hull. Classifiers on the convex hull obtain the best accuracy for some class distributions. Our class distribution consist of + and -. The ratio -/+ tells us the slope for iso-accuracy lines. \n",
    "\n",
    "Let $y = mx + b$ be the equation defining our iso-accuracy line, we have $m = neg / pos$ and the family of iso-accuracy lines is given by changing b. Notice that, higher lines are more desirable.\n",
    "\n",
    "To sum up, which classifiers are optimal in a certain environment? Depends on the ratio of the corresponding classes, we can think it as the range of + and -. Lets give an example for a specific environment where our ratio is 1 (we have the same quantity of pos and neg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.style.use('ggplot')\n",
    "#Add the 3 roc curves\n",
    "names = ['A','B','C1_0.5','C2_0.3','C3_0.6']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.4f})'\n",
    "                                   ''.format(names[i], roc_auc[i]), linewidth=1.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Draw line path of convex hull, skipping the first path \"diagonal\"\n",
    "iterpoint = iter(hull.simplices)\n",
    "next(iterpoint)\n",
    "for simplex in iterpoint:\n",
    "    plt.plot(points[simplex, 0], points[simplex, 1], '#ff3300', lw=6, alpha=0.5)\n",
    "    \n",
    "# dots\n",
    "plt.plot(points[:,0], points[:,1], 'o', color = '#7a7a52', alpha=0.5)\n",
    "#middle line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "#Iso-accuracy line\n",
    "x = np.linspace(0, 1, 3)\n",
    "y = 1. * (x) + 0.57 # line with 0.2 slope\n",
    "plt.plot(x, y, linewidth=2.0)\n",
    "\n",
    "#margins\n",
    "plot_margin = 0.02\n",
    "x0, x1, y0, y1 = plt.axis()\n",
    "plt.axis((x0 - plot_margin,\n",
    "          x1 + plot_margin,\n",
    "          y0 - plot_margin,\n",
    "          y1 + plot_margin))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the line in green with $y = m*x + 0.57$ where $m = neg / pos = 1$ the first one to touch the line is classifier C with a threshold of 0.6. Therefore, under this enviornment you should choose C3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0066cc\"> 2.2 Exercise 2: Model selection </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a 2-dimensional dataset with 1000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=1000,centers=4, n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: we used 4 centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see a scatter plot of all the points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], marker='^')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.2.1 Use 10-fold crossvalidation and plot k against the misclassification rate. Which value of k should you pick?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn import cross_validation\n",
    "n_samples = len(X)\n",
    "kf = cross_validation.KFold(n_samples, n_folds=10, shuffle=False, random_state=0)\n",
    "error_total = np.zeros([49, 1], dtype=float)\n",
    "for k in range(1,50):\n",
    "    error = []\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        error.append( zero_one_loss(y_test, clf.predict(X_test)) )\n",
    "    error_total[k-1, 0] = np.array(error).mean()\n",
    "    \n",
    "#Plot    \n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "x = np.arange(1,50, dtype=int)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(x, error_total[:, 0], '#009999', marker='o')\n",
    "plt.xticks(x, x)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('Missclasification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in the graph, the missclassification is low when we set k = 11. K=11 has 0.066, K=12 has 0.071 and k=21 has 0.069 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Do the same but with 100 bootstrapping repeats. What does the bias-variance trade-o\u000b",
    " look like for low and high values of k?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly draw with ShuffleSplit and use the same cross validation iterator to do the 100 bootstrapping repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = len(X)\n",
    "kf = cross_validation.ShuffleSplit(n_samples,n_iter=100, test_size=0.1, train_size=0.9, random_state=0)\n",
    "error_total = np.zeros([49, 1], dtype=float)\n",
    "for k in range(1,50):\n",
    "    error = []\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        error.append( zero_one_loss(y_test, clf.predict(X_test)) )\n",
    "        # error.append( 1. - clf.score(X_test, y_test) ) #, accuracy_score(y_test, clf.predict(X_test))\n",
    "    error_total[k-1, 0] = np.array(error).mean()\n",
    "\n",
    "#Plot    \n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "x = np.arange(1,50, dtype=int)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(x, error_total[:, 0], '#009999', marker='o')\n",
    "# plt.errorbar(x, accuracy_lst[:, 0], accuracy_lst[:, 1], linestyle='None', marker='^')\n",
    "plt.xticks(x, x)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('Missclasification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smalles missclassification error is k=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the variance and bias^2 ..........."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 What if you generate a dataset with 10000 examples, is the result still the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sample space of 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn import cross_validation\n",
    "X, y = make_blobs(n_samples=1000,centers=4, n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold crossvalidation and plot k against the misclassification rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = len(X)\n",
    "kf = cross_validation.KFold(n_samples, n_folds=10, shuffle=False, random_state=0)\n",
    "error_total = np.zeros([49, 1], dtype=float)\n",
    "for k in range(1,50):\n",
    "    error = []\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        error.append( zero_one_loss(y_test, clf.predict(X_test)) )\n",
    "    error_total[k-1, 0] = np.array(error).mean()\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "x = np.arange(1,50, dtype=int)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(x, error_total[:, 0], '#009999', marker='o')\n",
    "plt.xticks(x, x)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('Missclasification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 100 bootstrapping repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples = len(X)\n",
    "kf = cross_validation.ShuffleSplit(n_samples,n_iter=100, test_size=0.1, train_size=0.9, random_state=0)\n",
    "error_total = np.zeros([49, 1], dtype=float)\n",
    "for k in range(1,50):\n",
    "    error = []\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        error.append( zero_one_loss(y_test, clf.predict(X_test)) )\n",
    "        # error.append( 1. - clf.score(X_test, y_test) ) #, accuracy_score(y_test, clf.predict(X_test))\n",
    "    error_total[k-1, 0] = np.array(error).mean()\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "x = np.arange(1,50, dtype=int)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(x, error_total[:, 0], '#009999', marker='o')\n",
    "# plt.errorbar(x, accuracy_lst[:, 0], accuracy_lst[:, 1], linestyle='None', marker='^')\n",
    "plt.xticks(x, x)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('Missclasification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, from comparing visually both graphs they look the same; there is no remarkable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Repeat step 1-3, this time optimizing the hyperparameters of a decision tree. Choose the hyperparameter(s) that you think have the largest impact and use sensible value ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we build a decision tree classifier and select the maximum depth as the first hyper parameter. We used GridSearchCV to optimize the maximum depth hyperparameter using a range of [1,10]. We plot the accuracy vs the maximum depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# Create dataset\n",
    "X, y = make_blobs(n_samples=1000,centers=4, n_features=2, random_state=0)\n",
    "# First hyper-parameter: max. depth \n",
    "depth = range(1,11)\n",
    "# parameter distribution\n",
    "param_dist1 = dict(max_depth=depth)\n",
    "# Decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "# Grid seaarch\n",
    "grid = GridSearchCV(clf1, param_dist1, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "# print scores of grid search\n",
    "grid.grid_scores_\n",
    "grid_mean_scores =[result.mean_validation_score for result in grid.grid_scores_]\n",
    "# print best scores, parameters\n",
    "print \"Best score:\"\n",
    "print grid.best_score_\n",
    "print \"Best parameter:\"\n",
    "print grid.best_params_\n",
    "# plot the scores\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(grid_mean_scores)\n",
    "plt.xlabel('Maximum depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second parameter we optimize is the minimum leaf samples. The range we use here is [1,10]. The plot of accuracy vs minimum leaf samples is plotted to observe the variation of accuracy with the number of minimum leaves chosen,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second hyper-parameter: min. samples \n",
    "minsamples = range(1,11)\n",
    "# parameter distribution\n",
    "param_dist2 = dict(min_samples_leaf=minsamples)\n",
    "# Decision tree classifier\n",
    "clf2 = DecisionTreeClassifier()\n",
    "# Grid seaarch\n",
    "grid = GridSearchCV(clf2, param_dist2, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "# print scores of grid search\n",
    "grid.grid_scores_\n",
    "grid_mean_scores =[result.mean_validation_score for result in grid.grid_scores_]\n",
    "# print best scores, parameters\n",
    "print \"Best score:\"\n",
    "print grid.best_score_\n",
    "print \"Best parameter:\"\n",
    "print grid.best_params_\n",
    "# plot the scores\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(grid_mean_scores)\n",
    "plt.xlabel('Minimum leaf samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we select a pair of hyperparameters to optimize. These hyperparameters are the maximum depth and minimum leaf samples (a combination of the parameters chosen before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameter distribution\n",
    "param_dist3 = dict(max_depth=depth, min_samples_leaf=minsamples)\n",
    "# Decision tree classifier\n",
    "clf3 = DecisionTreeClassifier()\n",
    "# Grid search\n",
    "grid = GridSearchCV(clf3, param_dist3, cv=10, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "# print scores of grid search\n",
    "grid.grid_scores_\n",
    "grid_mean_scores =[result.mean_validation_score for result in grid.grid_scores_]\n",
    "# print best scores, parameters\n",
    "print \"Best score:\"\n",
    "print grid.best_score_\n",
    "print \"Best parameter:\"\n",
    "print grid.best_params_\n",
    "# plot the scores\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(grid_mean_scores)\n",
    "plt.xlabel('Parameter combination')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now we repeat all steps __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000,centers=4, n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n= 1000 K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn import cross_validation\n",
    "n_samples = len(X)\n",
    "kf = cross_validation.KFold(n_samples, n_folds=10, shuffle=False, random_state=0)\n",
    "error_total = np.zeros([49, 1], dtype=float)\n",
    "for k in range(1,50):\n",
    "    error = []\n",
    "    # clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        error.append( zero_one_loss(y_test, clf.predict(X_test)) )\n",
    "    error_total[k-1, 0] = np.array(error).mean()\n",
    "    \n",
    "#Plot    \n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "x = np.arange(1,50, dtype=int)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(x, error_total[:, 0], '#009999', marker='o')\n",
    "plt.xticks(x, x)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('K values')\n",
    "plt.ylabel('Missclasification Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n= 1000 with 100 bootstrapping repeats. bias variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with n = 10,000 K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with n = 10,000 bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2 style=\"color: #0066cc\"> 2.3 Exercise 3: Optimization </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the PenDigits dataset from OpenML (http://www.openml.org/d/32) into R or Python, and then create a separate test set with 20% of the instances using random stratifed sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from openml.apiconnector import APIConnector\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy import spatial\n",
    "\n",
    "apikey = 'fbc6d4b7868ce52640f6ec74cf076f48'\n",
    "connector = APIConnector(apikey=apikey)\n",
    "\n",
    "#loading data\n",
    "dataset = connector.download_dataset(32)\n",
    "X, y, attribute_names = dataset.get_dataset(target=dataset.default_target_attribute, return_attribute_names=True)\n",
    "iris = pd.DataFrame(X, columns=attribute_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size= 0.2, train_size=0.8, stratify= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the main hyperparameters (at least 2) of a decision tree learner (or SVMs) with a random search. Use nested resampling on the training set to obtain a clean evaluation. Evaluate your optimized hyperparameter settings on the separate test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we optimize 2 hyperparameters: min_samples_leaf and max_depth. We define a range of [1,10] for each of the chosen hyper -parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision tree obj.\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#define range for min samples\n",
    "minsamples = range(1,11)\n",
    "\n",
    "# define range of the depths.\n",
    "depth = range(1,11)\n",
    "\n",
    "# create dictionary with parameter lists.\n",
    "param_dist = dict(max_depth=depth, min_samples_leaf=minsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random search CV is used to identify the optimal set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          fit_params={}, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=5, refit=True,\n",
       "          scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random search cv with clf and parameter grid\n",
    "rand = RandomizedSearchCV(clf, param_dist, cv= 10, scoring = \"accuracy\", n_iter=10, random_state= 5)\n",
    "\n",
    "# fit the model.\n",
    "rand.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best set of parameters are identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.950415102923\n",
      "Best set of parameters:\n",
      "{'max_depth': 9, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# print results.\n",
    "rand.grid_scores_\n",
    "rand_mean_scores =[result.mean_validation_score for result in rand.grid_scores_]\n",
    "print \"Best score:\"\n",
    "print rand.best_score_\n",
    "print \"Best set of parameters:\"\n",
    "print rand.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree using the optimized paramters is evaluated on the separate test set. We then calculate the similarity between the actual labels and predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between lists of actual and predicted classes: \n",
      "98.2960172519\n"
     ]
    }
   ],
   "source": [
    "maxdep = rand.best_params_['max_depth']\n",
    "leaves = rand.best_params_['min_samples_leaf']\n",
    "\n",
    "# Use best parameters to evaluate\n",
    "clf1 = DecisionTreeClassifier(max_depth=maxdep, min_samples_leaf=leaves)\n",
    "clf1.fit(X_train,y_train)\n",
    "P = clf1.predict(X_test)\n",
    "sim = result = 1 - spatial.distance.cosine(P, y_test)\n",
    "print \"Similarity between lists of actual and predicted classes: \"    \n",
    "print sim*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(rand_mean_scores)\n",
    "plt.xlabel('Parameter combination')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Do the same, but this time don't use nested resampling: just optimize the hyperparameter settings on the training data. Do you get diferent optimized parameters? Also evaluate these on your separate test set. Which approach yields the best results? Explain your findings.\n",
    "#### Optimize these hyperparameters again (using nested resampling), but replace random search with a more intelligent approach, e.g. iterated F-racing. Plot the number of evaluations against the perfor- mance of the best hyperparameters up till then, for both approaches. Which approach finds good hyperparameter settings faster? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the next 2 sections, we use Grid search cv (instead of iterated f-racing) to optimize the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use grid search\n",
    "clf = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(clf, param_dist, cv=10, scoring='accuracy')\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:\n",
      "0.955760263846\n",
      "Best set of parameters:\n",
      "{'max_depth': 10, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "grid.grid_scores_\n",
    "grid_mean_scores =[result.mean_validation_score for result in grid.grid_scores_]\n",
    "# print best results and parameters\n",
    "print \"Best Score:\"\n",
    "print grid.best_score_\n",
    "print \"Best set of parameters:\"\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between actual and predicted classes: \n",
      "98.6556386182\n"
     ]
    }
   ],
   "source": [
    "maxdep = grid.best_params_['max_depth']\n",
    "leaves = grid.best_params_['min_samples_leaf']\n",
    "\n",
    "# Use best parameters\n",
    "clf1 = DecisionTreeClassifier(max_depth=maxdep, min_samples_leaf=leaves)\n",
    "clf1.fit(X_train,y_train)\n",
    "P = clf1.predict(X_test)\n",
    "sim = result = 1 - spatial.distance.cosine(P, y_test)\n",
    "print \"Similarity between actual and predicted classes: \"    \n",
    "print sim*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(grid_mean_scores)\n",
    "plt.xlabel('Parameter combination')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, grid search CV performs better than random search CV. Grid search CV, though slower than random search cv, \n",
    "has better accuracy and hence a lower misclassification rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search CV doesn't search every combination of paramters, and hence is considerably faster in finding a suitable set of parameters. These parameters are almost as good as those returned by grid search CV and hence, random search CV is a good substitute for grid search CV. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
